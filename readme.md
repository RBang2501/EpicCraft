# Story Generator : Epic Craft

## Overview

The Story Generator is a Node.js script that leverages an external API to dynamically generate and publish stories. It utilizes the 'node-fetch' library to make HTTP requests and interacts with a cloud service to generate various components of a story, such as twists, titles, and continuations.

## Features

#### Dynamic story generation based on initial instructions and inputs.
#### API integration for loading language models and generating story elements.
#### Publishing functionality to share generated stories.

## Setup

### Install dependencies:

#### npm install


### Adjust the baseinstruct and baseinput constants to customize the initial story instructions and input.

## Usage

### Run the script to generate and publish a story.
### Follow the prompts and review the generated story components.
### Published stories are available through the external API.

## API Endpoints

### Payload Endpoint: https://television-doing-pharmacies-sucking.trycloudflare.com/v1/chat/completions
### Model Loading Endpoint: https://television-doing-pharmacies-sucking.trycloudflare.com/v1/internal/model/load

### Note that these links are autogenerated, make sure to add changes in the notebook



Comments : 
Some parts of the code are commented out for testing purposes. Uncomment them as needed.

## Model Information

### Model URL:
- The model used is hosted on Hugging Face.
- The default URL in the script is set to: [https://huggingface.co/TheBloke/MythoMax-L2-13B-GPTQ](https://huggingface.co/TheBloke/MythoMax-L2-13B-GPTQ)

### Branch:
- The script allows specifying a branch for the model.
- The default branch is set to: `gptq-4bit-32g-actorder_True`.

### Model Parameters:
- The script allows specifying additional command-line flags for the model using the `command_line_flags` variable.
- Some default flags are provided, such as `--n-gpu-layers 128`, `--load-in-4bit`, and `--use_double_quant`.

## Web UI Configuration

### API Integration:
- The script provides an option (`api` variable) to enable API functionality when starting the web UI.

### Web UI Commands:
- The `python server.py --share` command is used to start the web UI.
- Additional options, such as specifying the model and command-line flags, can be appended to the command.

## Model Download and Setup

### Model Download:
- The script checks if a model URL is provided and downloads the model from Hugging Face using a Python script named `download-model.py`.
- The downloaded model is placed in a folder named based on the URL and branch.

### Web UI Launch:
- After downloading the model, the script starts the web UI using the `python server.py` command.
- The script prints the full command used to launch the web UI, including model and flag specifications.

## Additional Notes

### Compatibility:
- The script addresses potential compatibility issues related to different versions of PyTorch (`torch` library).
- It dynamically adjusts the requirements based on the installed version of PyTorch.

### Flash Attention Module:
- The script attempts to install a module named `flash_attn` and uninstalls it if already present.

### Web UI Output:
- The script provides status messages during setup, including information about the Torch version, installed packages, and the launch command.


# License

This project is licensed under the MIT License.